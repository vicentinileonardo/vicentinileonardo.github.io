# Video Outpainting Localizer

04/2023 - 09/2023

## Project description

Deep learning model for video outpainting localization. The model is able to localize the outpainted region in a video frame and to generate a binary mask that highlights the outpainted region. The implementation is based on the [RAFT model](https://arxiv.org/pdf/2003.12039.pdf). 

The main goal of the project was to modify the RAFT model and in particular we focused on data augmentation and loss function. The model has achieved a F1 score of 0.786 on the test set.

Code not available due to non-disclosure agreement.

## Artifacts

<center>
  <div style="display: flex; flex-direction: row; justify-content: center; align-items: center; flex-wrap: wrap;">
    <a href="/projects/reports/video_outpainting_localizer.pdf" target="_blank" class="btn">
    <img src="/img/icons8-pdf-100.png" alt="Video" width="70%" height=auto>
    </a>
  </div>
</center>

## Team and role

Team size: 2

+ The project was carried with a pair programming approach. <br>
+ I was responsible for the implementation of the data augmentation and the loss function. <br>

## Tech stack

<center>
  <div style="display: flex; flex-direction: row; justify-content: center; align-items: center; flex-wrap: wrap;">
  <img src="https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=blue" alt="Python" style="margin: 5px;">
  <img src="https://img.shields.io/badge/Numpy-777BB4?style=for-the-badge&logo=numpy&logoColor=white" alt="NumPy" style="margin: 5px;">
  </div>
</center>

<br>
